<html>

<head>
    <title>Research Experience</title>
    <link rel="stylesheet" href="myCSS.css">
</head>

<button> <a href=".\Research\PhD_esummary.html">PhD Summary</a></button>
<button> <a href=".\Research\PhD.exe" download>FIR Filter Design Tool based on PhD Research</a></button>
<button> <a href=".\Research\MS_esummary.html">MS Summary</a></button>
<button> <a href=".\Research\MS_jsummary.html">MS Summary (Japanese)</a></button>

<body>
    <h1>Research experience (in chronological order)</h1>
    <h2>Past Works</h2>
    <p><b>Robotics:</b> This was my first work when I started my career as an Assistant Engineer after completing my MS.
        I designed some modules for mobile robots, including collision avoidance and path planning algorithms
        implemented in hardware.
    </p>
    <p><b>Signal Processing:</b> My MS thesis was on the early detection of defects in the industry piping due to corrosion and
        other wear and tear. The industry partner provided sample pipes while I developed the complete prototype
        hardware and software, implementing my own proposed algorithm. Acoustic signals were used in this work.
    </p>
    <p><b>Filtering: </b> During PhD I proposed new accurate and efficient maximally flat designs of digital filters,
        which resolved several issues in the existing designs. The work resulted in five journal papers, and I was
        awarded the PhD degree in just two years, which was a record in my department. I continued this work as a JSPS
        fellow for the next two years, which produced another five papers on several new designs of different types of
        digital filters, including differentiators, low/high pass filters, band pass/stop filters, and Hilbert
        Transformers.
    </p>
    <p><b>Numerical Differentiation: </b> Forward, backward, and central difference formulas are used for numerical
        differentiation. These formulas were available in the closed form for smaller orders of differentiation;
        however, iterative procedures were used for higher orders. During my PhD, I developed closed-form formulas for
        numerical differentiation of arbitrary order.
    </p>
    <p><b>3D Modeling and regularization for telepresence: </b> I joined Kitakyushu University in 2002, after two years of JSPS
        fellowship. Here I worked for almost five years. The main project here was 3D telepresence. I designed a
        multi-camera system to capture different views of a human user, which were stitched in real-time and sent to the
        other side of the network over UDP protocol. Another main algorithm I developed as a part of this project was
        for the regularization of 3D mesh. In this work, a laser scanner was used to capture the 3D point cloud. The
        irregular mesh was converted to a regular mesh, which was mapped to a 2D image for further processing. This 2D
        representation of 3D data resulted in huge savings of storage, and it allowed utilization of existing image
        processing techniques on 3D data.
    </p>
    <p><b>3D Navigation on Mobile Phones: </b> This was another project I completed at the University of Kitakyushu. The leading
        maps company, Zenrin, was our collaborator, which provided us 3D street maps comprising a very large number of
        vertex and edge data. I developed a software module to simplify these street maps and a new data structure to
        store the simplified version in a very small-sized file. The idea was to represent the buildings as the primary
        graphics objects of the map. The decoder could re-construct the building from just a few corners and
        representative colors.
    </p>
    <p><b>Human Machine Interaction: </b>My next job was at the Kyushu Institute of Technology, where I worked for 16 months. I
        joined the team which was developing robots that could naturally interact with humans. My role was to develop
        face and gesture recognition modules efficient enough for real-time operation. This was the time before Kinect
        appeared in the market and changed the whole paradigm. We gave a very successful demo at BrainIT 2007 for three
        days, and the audience found our robot very interesting. The most liked feature by the visitors was that the
        robot would take the commands only from the registered users whose facial picture was stored in her memory and
        ignore the others who continuously tried to gain her attention.
    </p>
    <p><b>Mixed Reality for home entertainment: </b>Next, I moved to A*STAR Singapore, where I worked in a very competitive
        environment. My institute (Institute for Infocomm Research) was the largest under A*STAR with over 600
        researchers, of which more than 60% were PhDs. I joined a team working on virtual dancing in a 3D virtual
        environment. A whole room was dedicated to this in which a user wearing shutter glasses would find him in a
        virtual club, where he could request 3D virtual human partners to dance. I was responsible for the gesture and
        motion recognition module. The dance moves of the user were recognized and replicated/responded to by the
        virtual partner for an interactive dancing experience. Our visitors found the experience very realistic. We
        demonstrated our technology at the World Technology Summit and Awards 2010 held at the TIME & LIFE Building New
        York. It was voted as one of six award finalists among the highly selected 23 nominees under the Entertainment
        category.
    </p>
    <p><b>Gaze adaptive smart HDR displays: </b>This was another major project I worked on in A*STAR. To overcome the limited
        number of discrete intensity levels a display can have, we tracked the user’s gaze and allocated more intensity
        levels to the region of interest. This is how the human eye works, as, at any moment, it can have a dynamic
        range of 2-3 orders but can adapt to different brightness levels to cover a range of more than ten orders. My
        role in this project was to develop the tone-mapping algorithm adaptive to the gaze, which would enhance details
        in the region of interest without inducing artifacts in other regions. I was also responsible for setting up the
        eye-tracking equipment.
    </p>
    <p><b>Mixed Reality Clothing:</b> After the release of Microsoft Kinect, there was a renewed interest in mixed reality
        applications. I wrote a proposal for virtual clothing with a few colleagues, which was awarded generous funding
        of more than 500K SGD. This was multi-disciplinary research that involved modules like (a) setting up the
        virtual mirror, which would look exactly like a real mirror, (b) automatic measurement of the user’s body
        dimensions, (c) customizing the 3D models of clothes to the user’s body, (d) capturing user’s movements and
        animating clothes mesh in real-time, and (e) providing a gesture-controlled interface for selection of clothes
        from the wardrobe. The project received an additional grant of 300K SGD by ETPL, the commercial wing of A*STAR.
        We partnered with a local company to develop the commercial product which was demonstrated at various locations
        such as metro stations, exhibits, and shopping malls. Fashion brands such as Triumph also partnered with us. A
        feature was added in the commercial product to capture a photo in a virtual dress and post it on Facebook.
        Besides dresses, a new collection of virtual accessories such as bags, watches, jewelry, and glasses was also
        included to try on. I worked as PI of this project during the research and commercialization phases. I looked
        over the development of different modules for four years by a team of 8 PhD researchers and a few engineers. I
        was also responsible for meeting up with the industry representatives and demonstrate the technology. After the
        project completion, we received funding to spinoff a company, and our program manager took the initiative and
        launched this company in Singapore and China.
    </p>
    <p><b>Remote Surveillance:</b> This was my first major project at the University of Jeddah, and Lockheed Martin funded it.
        It was a very competitive grant given to only seven projects in the Kingdom. We installed a network of
        heterogeneous sensors to build an invisible security wall in more than a 100 m x100 m large area under this
        project. Any detected intrusion was processed at the edge, and the video data was transmitted to the server only
        when an anomaly was suspected. This saved a considerable amount of bandwidth. I worked as the PI of this project
        and overlooked the design and development of different hardware and software modules and outdoor installation.
        We gave several live demos of the system.
    </p>
    <p><b>Removal of ghosting Artifacts in HDR content:</b> HDR images are generally obtained by merging several LDR frames
        captured at different camera exposure settings. If moving objects in the scene change their locations across the
        merged frames, ghost-like artifacts can appear in the HDR images. Removal of these artifacts requires motion
        compensation in the LDR frames before merging. However, this is a slow process in the existing techniques and
        works only when the displacement of objects across frames is small. In this research, a more accurate and highly
        efficient approach is developed, which can be used in real-time. It can potentially be implemented on the camera
        hardware for real-time ghost-free HDR capturing.
    </p>

    <h2>Recent Works</h2>
    <p><b>Backward Compatible HDR Encoding:</b> One challenge in the High Dynamic Range domain is to ensure backward
        compatibility of HDR content such that they become displayable on the existing non-HDR TV sets as well. New HDR
        standards like HDR10 cater for HDR displays only, and therefore the content producers have to release a separate
        low dynamic range (LDR) version of each HDR movie for the older TV sets. In the past, some backward compatible
        formats such as JPEG-XT were proposed, but they did not gain industry acceptance due to inefficient coding, both
        in terms of compression and computation. I am working on a single format for both HDR and LDR displays. To
        achieve real-time performance, I developed an inverse tone-mapping algorithm that works for all existing TMOs
        and uses only a simple arithmetic operation. The new format leverages this inversion algorithm. The technique
        has been implemented on GPU for real-time performance, which is under review in an IEEE Transaction. A student
        is implementing it on FPGA.
    </p>
    <p><b>Generic HDR Tone-mapping Operator:</b> One solution for visualizing HDR content on LDR displays is to perform
        tone-mapping in real-time. This can allow the release of only one version of HDR content. However, in the
        presence of a plethora of different algorithms of varying complexity and content-dependent performance, it is
        not an easy task for the display manufacturers to incorporate the tone-mapping algorithm in their hardware. I
        have developed a generic algorithm such that any global tone-mapping algorithm can be implemented with the same
        hardware, utilizing 256 multiplications. Only the multiplication coefficients need to change from one
        tone-mapping algorithm to other. The TV manufacturers can add this simple implementation to their hardware, and
        the content producers can include these 256 coefficients in their HDR content. This way, the same copy of the
        content can be displayed on both HDR and LDR displays. For this research, all validation studies have been done.
        A student is incorporating it in HEVC, HDR10, and Dolby Vision formats’ pipelines.
    </p>
    <p><b>HDR Video Tone-mapping:</b> While there are several HDR tone-mapping algorithms available in the literature, some
        have high complexity, and others do not necessarily perform well for all types of content. In 2018, I published
        a new algorithm in IEEE Transactions on Industrial Electronics, which outperforms the existing state-of-the-art
        algorithms and works in real-time. One of my students simplified its operations and implemented it on FPGA.
        Next, he is extending it for video. The major issues in applying tone-mapping independently to video frames are
        flickering and temporal incoherence. This research is an attempt to addressing these issues in real-time.
    </p>
    <p><b>Tone-mapping adapted to outdoor viewing:</b> When our mobile phones are used outdoors in bright environments, the
        images on their screen do not look sharp enough. The idea behind this work is to use the human visual system’s
        response to environmental conditions and modify the tone-mapping curve to produce sharp images for different
        viewing conditions.
    </p>
    <p><b>Metaheuristics for image tone-mapping:</b> Recently, several quantitative metrics have been developed to measure the
        quality of tone-mapped images. Metaheuristics-based differential evolution algorithm can iteratively refine the
        tone-mapped images using these metrics as the fitness functions. I have obtained some promising results using
        this approach in this currently ongoing work.
    </p>
    <p><b>A new image quality metric:</b> The existing quality metrics are not suitable for all types of HDR content. I have
        produced several examples where a very high score is given by the metric to a visually distorted image. In this
        research, the reasons behind the shortcomings of the existing metrics are investigated. A new metric is
        proposed, which has a very high correlation with the scores given by the human subjects to the images to
        describe their quality.
    </p>
    <p><b>Big Data Clustering:</b> K-means and its variants are slow on big data. Moreover, they are sensitive to the initial
        solution and have the tendency to converge to a locally optimal solution. These issues are addressed in the
        proposed clustering algorithm, which can cluster 10 million samples to 1000 clusters in a few minutes – a task
        that the traditional k-means algorithm and its variants would take weeks to complete. The proposed algorithm is
        particularly useful on the image data and is the basis of several enhancement techniques I am currently working
        on.
    </p>
    <p><b>Medical Image Enhancement:</b> Medical images, including CT scans and MRI, capture HDR data, but they generally look
        dark on standard display screens. Existing tone-mapping techniques focus on keeping the naturalness of the
        scene; however, preserving the structure is more important for the medical images. This research focuses on
        contrast enhancement of the medical images while preserving their structure. Based on feedback from the medical
        practitioners, the produced images are visually better and are helpful in diagnosis.
    </p>
    <p><b>Mobile License Plate Recognition:</b> The existing license plate recognition systems used for access control and law
        enforcement use fixed cameras. This research focuses on plate recognition in a live video captured by a mobile
        device mounted on a vehicle. A deep neural network is used to detect the plate and recognize the alphanumeric
        characters. Compared to some existing commercial applications, the accuracy of the developed system is
        significantly high.
    </p>
    <p><b>8K Video:</b> Another exciting area I have just started exploring is the 8K video. There are exciting opportunities
        in this field in streaming, encoding, and backward compatibility.
    </p>
    <p><b>Machine learning for medical diagnostics:</b> Medical data (ECG/EEG signals or medical images) can be used for early
        diagnosis of disease. The signals/images from a patient’s organs have less structural complexity. In this
        research, a new complexity feature is proposed, which can be used in several machine learning-based scenarios
        for a diagnosis with nearly 100% accuracy.
    </p>

</body>

</html>
